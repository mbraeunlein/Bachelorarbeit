\section{Klassifikation}
\label{Klassifikation}
Unter einer Klassifikation versteht man in der Informatik das Einteilen von Objekten in vorher festgelegte Klassen. Diese Einteilung wird von einem Algorithmus durchgeführt, der anhand von festgelegten Merkmalen jedem Objekt eine Klasse zuordnet. Einen solchen Algorithmus nennt man Klassifikator. Um die Qualität eines Klassifikators zu analysieren, gibt es verschiedene Metriken.
\begin{itemize}
\item Accuracy - Die Anzahl der richtig zugeordneten Klassen
\item Recall - Der Anteil der positiven Beispiele, die auch positiv klassifiziert wurden
\item Precision - Der Anteil der positiv klassifizierten Beispiele, die auch positiv sind
\end{itemize}
Ein Klassifikator benötigt vor der Phase der Klassifikation zunächst einmal eine Trainigsphase, in der er anhand von Beispielen lernt. Mit dem erlenten Wissen wird anschließend die Einteilung in die Klassen vorgenommen.\\
Es gibt viele verschiedene Ansätze für Klassifikatoren, von denen die Wichtigsten in einem open source Framework implementiert sind. Dieses Framework heisst Weka\footnote{\url{http://www.cs.waikato.ac.nz/ml/weka/index.html}} und wurde im praktischen Teil dieser Bachelorthesis verwendet.\\
Weka arbeitet unter anderem mit dem .arff\footnote{\url{http://weka.wikispaces.com/ARFF}} Format. In einer .arff Datei befindet sich neben den Metadaten hauptsächlich eine Sammlung von Featurevektoren. Jeder Featurevektor beschreibt ein zu klassifizierendes Objekt. Ein Eintrag in einem Featurevektor beschreibt eine Eigenschaft dieses Objekts. Das könnte bei Fahrzeugen zum Beispiel die Anzahl der Reifen sein. Bezogen auf Sudokus bedeutet das, dass jedes Sudoku durch einen Featurevektor beschrieben wird. Jede zur Klassifikation verwendete Eigenschaft eines Sudokus ist dann ein Wert im entsprechenden Featurevektor. Die Schwierigkeitsgrade der Sudokus sind die vorgegebenen Klassen.\\
Jeder Klassifikator in Weka hat als Eingabe eine Liste von Featurevektoren. Möchte man also das Zuordnen von Sudokus zu Schwierigkeitsgraden mit Weka realisieren, dann muss eine Methode entwickelt werden, die aus einem gegebenen Sudoku einen Featurevektor extrahiert.\\
Bei der Klassifikation wird ein Verfahren angewendet, das als \textit{cross validation} bekannt ist und auch von Weka zur Verfügung gestellt wird. Dabei werden die Daten in eine vorgegebene Anzahl gleich großer Folds eingeteilt. Ein Fold ist eine Sammlung von Featurevektoren. Wenn die Einteilung in k Folds erfolgt ist, dann wird der Klassifikator k mal ausgewertet, einmal mit jedem Fold.\\
Der, in dieser Arbeit verwendete, Klassifikator ist J48, dabei handelt es sich um eine Java Implementierung von C4.5.  Dieser Algorithmus baut während der Lernphase einen Entscheidungsbaum auf. Dazu wird ein Feature ausgewählt. Alle Featurevectoren, deren Wert dieses Features größer ist, werden zusammen in einen Subtree eingeordnet, alle anderen Featurevectoren in den anderen Subtree. Für Features mit nominalen Werten wird für jeden Wert im Wertebereich ein eigener Unterbaum erzeugt und die Featurevectoren entsprechend zugeordnet. So entsteht der Entscheidungsbaum.\\
In der Phase der Klassifikation wird dann für jedes zu klassifizierende Objekt der Baum von der Wurzel an traversiert. Entsprechend der Einträge im Featurevector entscheidet der Algorithmus dann, in welchem Unterbaum die Suche fortgesetzt wird. Zum Aufbau des Entscheidungsbaums werden zwei Parameter benötigt, C und M. C ist eine Schwelle, die angibt, aber welcher Gewissheit der Entscheidungsbaum abgeschnitten wird. Je höher C ist, deste eher werden Unterbäume abgeschnitten und desto kleiner ist der Baum. M gibt an, wie viele Objekte in einem Knoten mindestens vorhanden sein müssen. Wenn nach einer weiteren Aufteilung weniger Objekte in den entstehenden Knoten wären, dann wird keine Aufteilung vorgenommen.\cite[chapter 6.1]{Witten2011}\\
In Kapitel \ref{Parameteroptimierung} wird erklärt, wie diese Parameter gewählt wurden.\\
Bei J48 handelt es sich um einen genauen Klassifikator, der nicht nur Einblicke in die Ergebnisse gewährt, sondern zusätzlich noch den Entscheidungsbaum ausgibt, an dem abgelesen werden kann, welche Features für die Klassifikation besonders relevant waren und welche Features weniger wichtig waren.\\
Die Qualität der resultierenden Klassifikation ist neben der Wahl der Parameter sehr stark von der Wahl der Einträge des Featurevektors abhängig. Die Ermittlung der Features wird daher in den nächsten Kapiteln sehr detailliert beschrieben.\\